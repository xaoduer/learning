
HTTP (HyperText Transfer Protocol,超文本传输协议) 是一个应用层协议，可用于分布协作式的超媒体系统。它是一个通用、无状态的协议。除了超文本，通过扩展它的请求方式，错误编码及首部，

还可以将它用于很多其它领域，比如域名服务器和分布式对象管理系统。HTTP的一个功能就是允许数据的类型变化和协商，从而允许独立于被传输的数据构建。

                                                                                                                                ——RFC 2616： HTTP/1.1 (1996年6月)

HTTP 0.9 : 只有一行的协议 （1991 ）
Tim Berners-Lee最初的HTTP建议是以简洁为出发点设计的，目的是推动他的另一个刚刚萌发的思想——万维网的应用。1991年，Tim Berners-Lee概述了这个新协议的动机，并罗列了几条宏观的设计目标。

HTTP 0.9 宏观的设计目标： 
    支持文件传输
    能够请求对超文本文档的索引搜索
    格式化 协商机制
    能够把客户端引导至不同的服务器


为了实际验证这个理论，构建出的简单原型：

    客户端请求是一个ASCII字符串
    客户端请求由一个回车符（CRLF）结尾
    服务器响应是一个ASCII字符串
    服务器响应的是一种超文本标记语言（HTML）
    连接在文档传输完毕后断开


最终的实现如下：

get /api/rpc/v1/client/animal/find/clientLb/xiaom http/0.9



HTTP 0.9的请求只有一行，响应是一个HTML（这里服务端返回json串），没有首部和其它元数据，只有响应正文。

总结HTTP 0.9的功能：
客户端/服务器、请求/响应协议
ASCII协议，运行于TCP/IP链接之上
设计用来传输超文本文档
服务器与客户端之间的连接在每次请求之后都会关闭
HTTP 1.0：迅速发展及参考性RFC
    随着人们对新兴Web的需求越来越多，HTTP 0.9很多根本性不足便暴露出来。人们需要一种协议，它不仅能访问超文本文档，还能提供有关请求和响应的各种元数据，而且要支持内容协商，等等。

Web开发者社区推出了大量实验性的HTTP服务器和客户端实现，基本上遵守实现，部署，推广采用的流程。在这些实验性开发的基础上，出现了一套最佳实践和共用模式，于是，1996年，HTTP工作组发布了RFC 1945，

解释说明了当时很多HTTP 1.0实现的"公共用法"。不过，这个RFC只是参考性的，HTTP 1.0并不是一个正式的规范或互联网标准！



本地测试服务采用HTTP 1.0协议发起请求被自动转换为HTTP 1.1应答

get /api/rpc/v1/client/animal/find/clientLb/xiaom http/1.0



     本地DOS命令使用HTTP1.0协议请求HTTP服务器




                                              HTTP 1.0请求响应头参数
HTTP1.0相比于HTTP 0.9，该协议的关键变化：
请求可以由多行首部字段构成；
响应对象前面添加了一个响应状态行；
响应对象也有自己的由换行符分隔的首部字段；
响应对象不局限于超文本；
服务器与客户端之间的连接在每次请求之后都会关闭。


    需要注意的是请求和响应首部都使用ASCII编码，但响应对象本身可以是任何类型。 HTML文件、纯文本文件、图片，或其它内容类型。事实上，HTTP中的“HTT”(Hypertext Transfer，超文本传输)在协议出现后不久就已经用词不当了。

在实践中，HTTP迅速发展为超媒体传输协议，但最初的名词沿用至今。

    除了媒体类型协商，RFC还解释了很多已经被实现的其它功能：内容编码、字符集支持、多部分类型、认证、缓存、代理行为、日期格式，等等。



    HTTP 1.0对每个请求都打开一个新的TCP连接严重影响性能

HTTP 1.1 ：互联网标准
    将HTTP转为IETF正式互联网标准的工作，与通过RFC 1945说明解释HTTP 1.0是并行展开的，从1995年到1999年，大致经历了4年时间。事实上，就在HTTP1.0发布大约6个月之后，也就是1997年1月，

定义正式HTTP 1.1标准的RFC 2068也发布了。又过了两年半，即到1999年6月RFC2616发布，又在标准中集合了很多改进和更新。



    HTTP 1.1理清了之前版本中有很多有歧义的地方，而且加入了很多重要的性能优化：持久连接、分块编码传输、字节范围请求、增强的缓存机制、传输编码及请求管道。

    HTTP1.1 改变了HTTP协议的语义，默认使用持久连接。换句话说，除非明确告知（Connection: close首部），否则服务器默认会保持连接打开。



    不过，这个功能也反向移植到了HTTP 1.0,可以通过Connection: Keep-Alive首部来启用。实际上，如果你使用的是HTTP 1.1，从技术上说不需要Connection : Keep-Alive首部，但很多客户端还是选择加上它。

此外，HTTP 1.1协议添加了内容、编码、字符集，甚至语言的协商机制，还添加了传输编码、缓存指令、客户端cookie等十几个可以每次请求协商的字段。



本地测试服务采用HTTP 1.1协议发起请求

get /api/rpc/v1/client/animal/find/clientLb/xiaom http/1.1

host:localhost



HTTP 1.1请求响应结构：


改进HTTP的性能是HTTP 1.0工作组的一个重要目标，HTTP 1.1也引入了大量增强性能的重要特性:

    持久化连接以支持连接重用；
    分块传输编码以支持流式响应；
    请求管道以支持并行请求处理；
    字节服务以支持基于范围的资源请求；
    改进的更好的缓存机制；


持久连接的优点：

    HTTP 1.1的一个主要改进就是引入了持久HTTP连接。为了简单起见，我们限定最多只有一个TCP连接，并且只取得两个小文件(每个<4 KB):一个HTML文档，一个CSS文件，服务器响应需要不同的时间（分别为40ms和20ms）。伦敦到纽约的光纤延迟为28ms

每个TCP连接开始都有三次握手，要经历一次客户端与服务器间完整的往返。此后，会因为HTTP请求和响应的两次通信而至少引发另一次往返，最后，还要加上服务器处理时间，才能得到每次请求的总时间。

通过单独的TCP连接取得HTML和CSS文件(HTTP 1.0)：


    服务器处理速度越快，固定延迟对每个网络请求总时间的影响就越大！所以，最简单的优化就是重用底层连接，添加对HTTP持久连接的支持，就可避免第二次TCP连接时的三次握手，消除另一次TCP慢启动的往返，节约整整一次网络延迟。

由上述流程可以看出，在N次请求下，持久连接节省的总延迟=（N-1）*RTT

持久TCP连接取得HTML和CSS文件（HTTP 1.1）：




HTTP管道（HTTP 1.1）：
    持久HTTP可以让我们重用已有的连接来完成多次应用请求，但多次请求必须严格满足FIFO的队列顺序：发送请求，等待响应完成，再发送客户端队列中的下一个请求。

HTTP管道流是一个很小但对上述工作流却非常重要的一次优化，管道可以让我们把FIFO队列从客户端（请求队列）迁移到服务器（响应队列）。



使用HTTP管道发送请求，服务器端按FIFO处理队列



    HTTP 1.1管道的好处，就是消除了发送请求和响应的等待时间。这种并行处理请求的能力对提升应用性能的帮助非常之大。

    通过对HTTP的连接优化，从一开始的每个请求要用两个TCP连接总延迟284ms，到使用持久连接后避免了一个握手往返，时间减少为228ms。最后通过使用HTTP管道，又减少了两次请求之间的一次往返，总延迟时间减少为172ms，减少了40%的延迟时间。

当网络延迟越高，请求越多时，节省的时间就越多。(284ms—228ms—172ms)



HTTP 1.x的局限性：

    服务器可以并行处理请求，理论上讲，没有障碍可以组织服务器同时处理管道中的请求，从而再减少20ms的延迟。可惜的是，HTTP 1.x只能严格串行地返回响应。特别的，HTTP 1.x不允许一个连接上多个响应数据交错到达（多路复用），

因而一个响应必须完全返回后，下一个响应才会开始传输。

    

服务器并行处理的情况：



     HTML和CSS请求同时到达，但先处理的是HTML请求；
    服务器并行处理两个请求，其中处理HTML用时40ms，处理CSS用时20ms;
    CSS请求先处理完成，但被缓冲起来以等候发送HTML响应；
    发送完HTML响应后，再发送服务器缓冲中的CSS响应。
即使客户端同时发送了两个请求，而且CSS资源先准备就绪，服务器也会先发送HTML响应，然后交付CSS。这种情况通常被称为队首阻塞。



HTTP管道存在的问题： 

    一个慢响应就会阻塞所有的后续请求；
   并行处理请求时，服务器必须缓冲管道中的响应，从而占用服务器资源，如果有个响应非常大，则很容易形成服务器的受攻击面；
   响应失败可能终止TCP连接，从而强迫客户端重新发送对所有后续资源的请求，导致重复处理；
   由于可能存在中间代理，因此检测管道兼容性，确保可靠性很重要；
   如果中间代理不支持管道，那它可能会中断连接，也可能会把所有的请求串联起来；


SPDY(speedy的缩写):HTTP 2.0的催化剂
    SPDY是谷歌开发的一个实验性协议，于2009年年中发布，主要目标是通过解决HTTP 1.1中广为人知的一些性能限制，来减少网页的加载延迟，大致上目标设定如下：

页面加载时间（PLT,Page Load Time）降低50%
无需网站作者修改任何内容；
把部署复杂性降至最低，无需变更网络基础设施
与开源社区合作开发这个新协议；
收集真实性能数据，验证这个实验性协议是否有效；


    为了达到降低50%页面加载时间的目标，SPDY引入了一个新的二进制分帧数据层，以实现多向请求和响应、优先次序、最小化及消除不必要的网络延迟、目的是更有效地利用底层TCP连接。

SPDY在被行业采用并证明能够大幅度提升性能之后，已经具备了成为一个标准的条件。最终，HTTP-WG在2012年初把HTTP 2.0提到了议事日程，吸取SPDY经验教训，并在此基础上制定官方标准。



HTTP 2.0：改进传输性能
    HTTP 2.0宣言草稿：

相对于使用TCP的HTTP 1.1，用户在大多数情况下的感知延迟要有实质上，可度量的改进；
解决HTTP中的 “队首阻塞”问题；
并行操作无需与服务器建立多个连接，从而改进 TCP的利用率，特别是拥塞控制方面；
保持HTTP 1.1的语义，利用现有文档，包括（但不限于）HTTP方法、状态码、URI，以及首部字段；
明确规定HTTP 2.0如何与HTTP 1.x相互操作，特别是在中间介质上；
明确指出所有新的可扩展机制以及适当的扩展策略
                                  ——HTTPbis WG宣言 HTTP 2.0



    HTTP的简单本质是它最初得以采用和后来快速发展的关键，在巨大成功的压力下，同时随着我们越来越多的把应用部署到Web上，HTTP的问题也出现了。今天，用户和Web开发者都迫切想要通过HTTP 1.1达到一种

近乎实时的响应速度和协议性能，而要满足这个需求，仅靠在原协议基础上修修补补是不够的。

为应对这些挑战，HTTP必须继续发展。HTTP工作组已经在2012年宣布开发HTTP2.0。



    当前，出现了一种保持HTTP语义，但脱离HTTP/1.x消息分帧及语法的协议用法。这种用法被证明有碍于性能，并且是在鼓励滥用底层传输协议。

    本工作组将制定一个新规范，从有序、半双工的角度重新表达当前HTTP的语义。与HTTP/1.x一样，主要将使用TCP作为传输层，不过也应该支持其他传输协议。

                                                                                                                           ——HTTP 2.0纲领(2012年1月)



    HTTP 2.0的目的就是通过支持请求与响应的多路复用来减少延迟，通过压缩HTTP首部字段将协议开销降至最低，同时增加对请求优先级和服务端推送的支持。

HTTP 2.0不会改动HTTP的语义，HTTP方法、状态码、URI及首部字段，等待这些核心概念一如往常。但是，HTTP 2.0修改了格式化数据(分帧)的方式，以及客户端与服务器间传输这些数据的方式。

二进制分帧层
    这里所谓的“层”，指的是位于套接字接口与应用可见的高层HTTP API之间的一个新机制，HTTP 2.0将所有的传输信息分割为更小的消息和帧，并对它们采用二进制格式编码。



流、消息和帧
    新的二进制分帧机制改变了客户端与服务器之间交互数据的方式，为了说明这个过程，我们需要了解HTTP 2.0的几个新概念

      流：已建立连接上的双向字节流
     消息：与逻辑消息对应的完整的一系列数据帧
     帧：HTTP 2.0通信的最小单位，每个帧包含帧首部，至少也会标识出当前帧所属的流


    所有的HTTP 2.0通信都在一个连接上完成，这个连接可以承载任意数量的双向数据流。相应地，每个数据以消息的形式发送，而消息由一个或多个帧组成，这些帧可以乱序发送，然后再根据每个帧首部的流标识符重新组装。

HTTP 2.0的所有帧都采用二进制编码，所有首部数据都会被压缩。因此，上图只是说明了数据流，消息和帧之间的关系，而非它们实际传输时的编码结果。



多向请求与响应
    客户端和服务器可以把HTTP消息分解为互不依赖的帧，然后乱序发送，最后再在另一端把它们重新组装起来。

    图中包含了同一个连接上多个传输中的数据流，客户端正在向服务器传输一个DATA帧（Stream 5）,与此同时，服务器正在向客户端乱序发送stream 1和stream 3的一系列帧。此时，一个连接上有3个请求/响应并行交换！



                                      HTTP 2.0在共享连接上同时发送请求和响应
有3个活动的流：stream1、stream3、stream5
3个流的ID都是奇数，说明都是客户端发起的
这里没有服务器发起的流
服务器发送的stream 1包含多个DATA帧，这是客户端之前请求的响应数据。这也说明在此前已经发送过HEADERS帧了
服务器在交错发送stream 1的DATA帧和stream 3的HEADERS帧，这就是响应的多路复用！
客户端正在发送stream 5的DATA帧，表明HEADERS帧之前已经发送过了


请求优先级
    每个流都可以带有一个31比特的优先值，0表示最高优先级。有了这个优先值，客户端和服务器就可以在处理不同的流时采取不同的策略，以最优的方式发送流、消息和帧。

服务器可以根据流的优先级，控制资源的分配（CPU、内存、带宽），在响应数据准备好之后，优先将最高优先级的帧发送给客户端。

流量控制
    在同一个TCP连接上传输多个数据流，就意味着要共享带宽。标定数据流的优先级有助于按序交付，但只有优先级还不足以确定多个数据流或多个连接间的资源分配。HTTP 2.0为数据流和连接的流量控制提供了一个简单的机制：

    流量控制基于每一跳进行，而非端到端的控制
    流量控制基于窗口更新帧进行，即接收方广播自己准备接收某个数据流的多少字节，以及对整个连接要接收多少字节
    流量控制窗口大小通过WINDOW_UPDTATE帧更新，这个字段指定了流ID和窗口大小递增值
    流量控制有方向性，即接收方可能根据自己的情况为每个流乃至整个连接设置任意窗口大小
    流量控制可以由接收方禁用，包括个别的流和针对整个连接
优先级可以决定交付次序，而流量控制则可以控制HTTP 2.0连接中每个流占用的资源：接收方可以针对特定的流广播教低的窗口大小，以限制它的传输速度。

服务器推送
    除了对最初请求的响应外，服务器还可以额外的向客户端推送资源，无需客户端明确请求。



                                               服务器发起推送资源的新流
    有了服务器推送后，HTTP 1.x时代的大多数插入或嵌入资源的做法基本上也就过时了。需要注意的是所有的服务器推送都由PUSH_PROMISE发端，PUSH_PROMISE帧中只包含要约（promise）资源的HTTP首部。

    遵循请求-响应的循环，只能借助对请求的响应推送资源，服务器不能随意发起推送流。其次，PUSH_PROMISE帧必须在返回响应之前发送，以免出现竞态条件。

首部压缩
    HTTP的每一次通信都会携带一组首部，用于描述传输的资源及其属性。在HTTP 1.x中，这些元数据都是以纯文本形式发送的，通常会给每个请求增加500-800字节的负荷。如果算上HTTP cookie，增加的负荷通常会达到上千字节。

为减少这些开销并提升性能，HTTP 2.0会压缩首部元数据 ：

    HTTP 2.0在客户端和服务端使用“首部表”来跟踪和存储之前发送的键—值对，对于相同的数据，不再通过每次请求和响应发送；
    首部表在HTTP 2.0的连续存续期内始终存在，由客户端和服务器共同渐进地更新；
    每个新的首部键—值对要么被追加到当前表的末尾，要么替换表中之前的值；


    在这个例子中，第二个请求只需要发送变化了的路径首部（:path）,其它首部没有变化，不用再发送了。这样就可以避免传输冗余的首部，从而显著减少每个请求的开销。

有效的HTTP 2.0升级与发现
    支持HTTP 2.0的客户端在发起新请求之前，必须能发现服务器及所有中间设备是否支持HTTP 2.0协议。有三种可能的情况：

    通过TLS和ALPN（Application Layer Protocol Negotiation）发起新的HTTPS连接；
    根据之前的信息发起新的HTTP连接；
    没有之前的信息而发起的新的HTTP连接；
HTTPS协商过程中有一个环节会使用ALPN，发现和协商HTTP 2.0的支持情况。整个过程分为以下步骤：

    客户端在ClientHello消息中追加一个新的ProtocolNameList字段，包含自己支持的应用协议
    服务器检查ProtocolNameList字段，并在ServerHello消息中以ProtocolName字段返回选中的协议


下图展示了TLS握手协议流程：



